# -*- coding: utf-8 -*-
"""sentiment_analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yPmpGhM9FAQDM8k124k5pLb0pwLKuVQV

# Kaggle Data Download Section

Kaggle API key kullanarak FER 2013 veri setinin indirilmesi ve zip halinden çıkarılarak kullanıma hazır hala getirilmesi bu bölümde yapılmıştır.
"""

from google.colab import files
files.upload()

! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets download -d msambare/fer2013
! unzip fer2013.zip

"""# Module Import Section

Projede kullanılacak olan harici modüller bu bölümde import edilmiştir. Algoritma, veri işleme ve model eğitimi için Tenserflow Keras kütüphanesinden yararlanılmıştır.
"""

import os
import random

import scipy
import numpy as np  # Maths operations
import pandas as pd  # Data operations
import matplotlib.pyplot as plt  # Visualization, plotting and analysis operationsfrom keras.models import load_model

from keras.models import load_model
from tensorflow.keras.utils import img_to_array
from tensorflow.keras.utils import img_to_array
from keras import regularizers
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D
from tensorflow.keras.layers import Dense, Dropout, Flatten
from tensorflow.keras.utils import load_img
from tensorflow.keras.preprocessing.image import ImageDataGenerator

"""# Data Prepration Section

Algoritmada kullanılacak olan veri setleri train (eğitim) ve test (validation) olmak üzere ikiye ayrılmıştır. 48x48 boyutunda ve siyah-beyaz; 48x48x1 shape sahip olarak okunacaktır (RGB yani renkli olmadığı için 1 olmuştur). Ayrıca **shuffle** parametresi ile veriler karıştırılarak okunmuş ve modelin doğruluğunun arttırılması hedeflenmiştir.
"""

train_datagenerator = ImageDataGenerator(rescale=1./255,
                                   zoom_range=0.3,
                                   horizontal_flip=True)

train_data = train_datagenerator.flow_from_directory(
        "train",
        target_size=(48,48),
        batch_size=64,
        color_mode = "grayscale",
        class_mode='categorical',
        shuffle=True
        )

train_data_count = train_data.samples
train_data.class_indices

val_datagenerator = ImageDataGenerator(rescale=1./255)

val_data = val_datagenerator.flow_from_directory(
        "test",
        target_size=(48,48),
        batch_size=64,
        color_mode = "grayscale",
        class_mode='categorical',
        shuffle=True
        )


val_data_count = val_data.samples
val_data.class_indices

plt.figure(figsize= (8,8))
for i in range(1, 7, 1):
    plt.subplot(2,3,i)
    img = load_img("train/happy/"+os.listdir("train/happy")[i], target_size=(48, 48))
    plt.imshow(img)
plt.show()

"""# Model Hazırlama ve Eğitim Kısmı

Bu aşamada kullanılacak olan CNN algoritmasının katmanları oluşturulmuş ve model hazırlanmıştır. Kullanılacak olan modelde kayıp fonksiyonu için **"Categorical Cross Entropy"** kullanılmış, **öğrenme katsayısı 0.0001** kullanılmıştır.

**Epoch** sayısı yani veri seti üzerinden yapılacak eğitim sayısı **60** seçilmiştir. Daha verimli sonuçlar için arttırılabilir ancak **over-fitting** durumları göz önünde bulundurulmalıdır.
"""

input_size = (48,48,1)

model = Sequential()

# 1 - Convolution
model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape =input_size))
model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))
model.add(BatchNormalization())
model.add(MaxPooling2D(2, 2))
model.add(Dropout(0.25))

# 2nd Convolution layer
model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01)))
model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

# 3rd Convolution layer
model.add(Flatten())
model.add(Dense(1024, activation='relu'))
model.add(Dropout(0.5))

model.add(Dense(7, activation='softmax'))

#Compliling the model
model.compile(optimizer=Adam(learning_rate=0.0001, decay=1e-6),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

hist = model.fit(
    train_data,
    steps_per_epoch=train_data_count // 64,
    epochs=60,
    validation_data=val_data,
    validation_steps=val_data_count // 64,
)

model.save("trained_model.h5")
!zip -r /content/modal.zip /content/trained_model.h5

from google.colab import drive
drive.mount('/content/drive')

!cp trained_model.h5 /content/drive/MyDrive

model = load_model("/content/drive/MyDrive/trained_model.h5")

"""# Model Değerledirme Kısmı

Modelin başarımını ölçmek için accuracy (doğruluk) değerleri; test verisi üzerinde kıyaslanmıştır. Detaylı grafik aşağıda verilmiştir.
"""

h = hist.history
plt.plot(h["accuracy"])
plt.plot(h["val_accuracy"], c="red")
plt.title("Accuracy vs Validation Accuracy")
plt.show()

plt.plot(h["loss"])
plt.plot(h["val_loss"], c="red")
plt.title("Loss vs Validation Loss")
plt.show()

"""# Tahminleme Kısmı

Tekil görseller üzerinde tahminlemeler yapılmıştır.
"""

emotions = dict(zip(train_data.class_indices.values(), train_data.class_indices.keys()))
emotions

path = "test/sad/"+random.choice(os.listdir("test/sad"))
img = load_img(path, target_size=(48, 48), color_mode="grayscale")

i = img_to_array(img) / 255
input_arr = np.array([i])
input_arr.shape

prediction = np.argmax(model.predict(input_arr))

print(f"Bu kişi: {emotions[prediction]}")
plt.imshow(load_img(path, target_size=(48, 48)))
plt.title("input image")
plt.show()